# -*- coding: utf-8 -*-
"""
AC-research â€” Streamlit ì›¹ ë¦¬ì„œì¹˜ ì•±.
ê²€ìƒ‰ì–´ í•˜ë‚˜ë¡œ ë¯¸êµ­ SEC / êµ­ë‚´ DART ì¬ë¬´ì œí‘œ, ìœ íŠœë¸Œ, ë…¼ë¬¸, ë¦¬í¬íŠ¸, ë‰´ìŠ¤ë¥¼ í•œ ë²ˆì— ê²€ìƒ‰í•˜ê³ 
ê²°ê³¼ë¥¼ ì—‘ì…€ë¡œ ë‹¤ìš´ë¡œë“œí•©ë‹ˆë‹¤.

ì‹¤í–‰ ë°©ë²• (í”„ë¡œì íŠ¸ ë£¨íŠ¸ì—ì„œ):
    streamlit run app.py
    (ë˜ëŠ”) python -m streamlit run app.py --server.port 8503
"""
import base64
import re
import sys
from io import BytesIO
from pathlib import Path

import pandas as pd
import streamlit as st
import streamlit.components.v1 as components

BASE_DIR = Path(__file__).resolve().parent

# .env íŒŒì¼ ë¡œë“œ (í”„ë¡œì íŠ¸ ë£¨íŠ¸)
try:
    from dotenv import load_dotenv
    load_dotenv(BASE_DIR / ".env")
except ImportError:
    pass
ASSETS_DIR = BASE_DIR / "assets"
LOGO_DIR = BASE_DIR / "assets" / "logos"
DATA_DIR = BASE_DIR / "data"
DATA_DIR.mkdir(parents=True, exist_ok=True)

if str(BASE_DIR) not in sys.path:
    sys.path.insert(0, str(BASE_DIR))

# apps/apië¥¼ sys.pathì— ì¶”ê°€í•´ app.config ì˜ì¡´ì„± í•´ê²°
_API_DIR = BASE_DIR / "apps" / "api"
if str(_API_DIR) not in sys.path:
    sys.path.insert(0, str(_API_DIR))

from src.paper_scraper import search_papers
from src.sec_scraper import collect_sec_links
from src.youtube_scraper import search_youtube_videos
from src.report_scraper import search_reports

# ë‰´ìŠ¤: apps/api/app/services/news.py ì§ì ‘ ì‚¬ìš©
try:
    from app.services.news import search_news_articles
    def news_api_configured() -> bool:
        import os
        news_key = (os.getenv("NEWS_API_KEY") or "").strip()
        naver_id = (os.getenv("NAVER_CLIENT_ID") or "").strip()
        naver_secret = (os.getenv("NAVER_CLIENT_SECRET") or "").strip()
        return bool(news_key or (naver_id and naver_secret))
except ImportError:
    from src.news_scraper import search_news_articles, news_api_configured

try:
    from src.dart_scraper import collect_dart_reports
    DART_AVAILABLE = True
except (ValueError, Exception):
    collect_dart_reports = None
    DART_AVAILABLE = False

_SLUG_BAD = re.compile(r"[\s\t/\\:?\"'*<>|]+")


def slugify(text: str) -> str:
    s = (text or "").strip().lower()
    s = _SLUG_BAD.sub("_", s)
    s = re.sub(r"_+", "_", s).strip("_")
    return s or "research"


def is_korea_stock(query: str) -> bool:
    """ì…ë ¥ì´ êµ­ë‚´ ì¢…ëª©ë²ˆí˜¸(ìˆ«ì 6ìë¦¬ ì´ìƒ)ì´ë©´ True."""
    q = (query or "").strip()
    digits_only = re.sub(r"\D", "", q)
    return len(digits_only) >= 6


def safe_logo_path(name: str) -> Path | None:
    p = LOGO_DIR / name
    if p.is_file():
        return p
    p = ASSETS_DIR / name
    if p.is_file():
        return p
    if name.endswith(".png"):
        fallback = ASSETS_DIR / (name.replace(".png", ".png.png"))
        if fallback.is_file():
            return fallback
    return None


def _img_b64(name: str) -> str:
    """ë¡œê³  íŒŒì¼ì„ base64 data URIë¡œ ë°˜í™˜. ì—†ìœ¼ë©´ ë¹ˆ ë¬¸ìì—´."""
    p = safe_logo_path(name)
    if p is None:
        return ""
    try:
        raw = Path(p).read_bytes()
        ext = Path(p).suffix.lstrip(".").lower()
        mime = "image/svg+xml" if ext == "svg" else f"image/{ext or 'png'}"
        return f"data:{mime};base64,{base64.b64encode(raw).decode()}"
    except Exception:
        return ""


# â”€â”€ í˜ì´ì§€ ì„¤ì • â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.set_page_config(page_title="AC-research", layout="wide")
st.title("AC-research")
st.markdown(
    "í‚¤ì›Œë“œ í•˜ë‚˜ë¡œ **ë¯¸êµ­ SEC / êµ­ë‚´ DART ì¬ë¬´ì œí‘œ**, **ìœ íŠœë¸Œ**, **ë…¼ë¬¸**, **ë¦¬í¬íŠ¸**, **ë‰´ìŠ¤**ë¥¼ "
    "í•œ ë²ˆì— ê²€ìƒ‰í•˜ëŠ” ë¦¬ì„œì¹˜ ë„êµ¬ì…ë‹ˆë‹¤."
)

# â”€â”€ ê²€ìƒ‰ ì˜ì—­ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
query_input = st.text_input(
    "ê²€ìƒ‰ì–´ ë˜ëŠ” í‹°ì»¤ (ì¬ë¬´ì œí‘œëŠ” ë¯¸êµ­ì£¼ì‹=í‹°ì»¤, êµ­ë‚´ì£¼ì‹=ì¢…ëª©ë²ˆí˜¸, ë‚˜ë¨¸ì§€=ê²€ìƒ‰ì–´ ì‚¬ìš©)",
    placeholder="ì˜ˆ: DIS, 005930, AI inference chip",
    key="query",
)

# â”€â”€ ì†ŒìŠ¤ ì„ íƒ í† ê¸€ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
_ALL_SOURCES = ["ì¬ë¬´ì œí‘œ(SEC)", "ì¬ë¬´ì œí‘œ(DART)", "ìœ íŠœë¸Œ", "ë…¼ë¬¸", "ë¦¬í¬íŠ¸", "ë‰´ìŠ¤"]
for _src in _ALL_SOURCES:
    if f"src_{_src}" not in st.session_state:
        st.session_state[f"src_{_src}"] = False

# ìˆ¨ê²¨ì§„ st.checkboxë¡œ ìƒíƒœ ê´€ë¦¬ (HTML ë²„íŠ¼ì´ JSë¡œ ì´ë¥¼ í´ë¦­)
import json as _json

# ìˆ¨ê¹€ CSS
st.markdown("""
<style>
div[data-testid="stCheckbox"] { display: none !important; }
</style>
""", unsafe_allow_html=True)

_cb_cols = st.columns(len(_ALL_SOURCES))
for _col, _src in zip(_cb_cols, _ALL_SOURCES):
    with _col:
        st.checkbox(_src, key=f"src_{_src}", label_visibility="collapsed")

# í˜„ì¬ ì„ íƒ ìƒíƒœ + ì†ŒìŠ¤ ëª©ë¡ì„ JSì— ì „ë‹¬í•´ ì»¤ìŠ¤í…€ pill ë²„íŠ¼ ë Œë”ë§
_states = {s: st.session_state[f"src_{s}"] for s in _ALL_SOURCES}
_states_json = _json.dumps(_states)
_sources_json = _json.dumps(_ALL_SOURCES)

components.html(f"""
<style>
  body {{ margin:0; padding:0; background:transparent; }}
  #pill-row {{
    display: flex;
    flex-wrap: wrap;
    gap: 6px;
    padding: 4px 0 2px 0;
  }}
  .pill {{
    padding: 4px 14px;
    font-size: 12.5px;
    font-weight: 500;
    border-radius: 999px;
    border: 1px solid rgba(255,255,255,0.22);
    background: rgba(255,255,255,0.06);
    color: rgba(255,255,255,0.75);
    cursor: pointer;
    white-space: nowrap;
    transition: background 100ms, border-color 100ms, color 100ms;
    line-height: 1.5;
    font-family: inherit;
    outline: none;
  }}
  .pill:hover {{
    background: rgba(255,255,255,0.13);
    border-color: rgba(255,255,255,0.40);
    color: #fff;
  }}
  .pill.on {{
    background: rgba(220,53,69,0.22);
    border-color: rgba(220,53,69,0.65);
    color: #ff8088;
    font-weight: 700;
  }}
  .pill.on:hover {{
    background: rgba(220,53,69,0.32);
    border-color: rgba(220,53,69,0.85);
    color: #ffb3b8;
  }}
</style>

<div id="pill-row"></div>

<script>
(function() {{
  var sources = {_sources_json};
  var states  = {_states_json};
  var row = document.getElementById('pill-row');

  sources.forEach(function(src) {{
    var btn = document.createElement('button');
    btn.className = 'pill' + (states[src] ? ' on' : '');
    btn.textContent = src;

    btn.addEventListener('click', function() {{
      // ë¶€ëª¨ Streamlit ë¬¸ì„œì—ì„œ í•´ë‹¹ ì†ŒìŠ¤ì˜ checkbox input ì°¾ì•„ í´ë¦­
      var labels = window.parent.document.querySelectorAll(
        'div[data-testid="stCheckbox"] label'
      );
      for (var i = 0; i < labels.length; i++) {{
        if (labels[i].textContent.trim() === src) {{
          labels[i].click();
          break;
        }}
      }}
    }});

    row.appendChild(btn);
  }});
}})();
</script>
""", height=42, scrolling=False)

options = [s for s in _ALL_SOURCES if st.session_state[f"src_{s}"]]

# â”€â”€ ë‹¨ì¼ ê²€ìƒ‰ ë²„íŠ¼ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
search_clicked = st.button("ê²€ìƒ‰", use_container_width=True)

# â”€â”€ ë‹¤ì¤‘ ê²€ìƒ‰ ì˜ì—­ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
multi_query_input = st.text_area(
    "ë‹¤ì¤‘ ê²€ìƒ‰ì–´ (ì¤„ë°”ê¿ˆìœ¼ë¡œ êµ¬ë¶„)",
    placeholder="ì˜ˆ:\nDIS\nAAPL\nAI inference chip",
    key="multi_query",
    height=120,
)
multi_search_clicked = st.button("ë‹¤ì¤‘ ê²€ìƒ‰", use_container_width=True)

# â”€â”€ ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
for _key in ["sec_df", "korea_sec_df", "yt_df", "paper_df", "report_df", "news_df", "excel_bytes"]:
    if _key not in st.session_state:
        st.session_state[_key] = None
if "download_filename" not in st.session_state:
    st.session_state.download_filename = "research.xlsx"


# â”€â”€ ê³µí†µ í—¬í¼: ë‹¨ì¼ ì¿¼ë¦¬ ê²€ìƒ‰ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def _run_single_search(q: str, opts: list, max_yt: int = 30, max_paper: int = 30,
                       max_report: int = 30, max_news: int = 30):
    """ë‹¨ì¼ ê²€ìƒ‰ì–´ qì— ëŒ€í•´ opts ì†ŒìŠ¤ë¥¼ ê²€ìƒ‰. ê²°ê³¼ dict ë°˜í™˜."""
    sec_df = korea_sec_df = yt_df = paper_df = report_df = news_df = None
    errors = []

    want_sec = "ì¬ë¬´ì œí‘œ(SEC)" in opts
    want_dart = "ì¬ë¬´ì œí‘œ(DART)" in opts

    if want_sec or want_dart:
        if is_korea_stock(q):
            # êµ­ë‚´ ì¢…ëª© â†’ DART
            if not DART_AVAILABLE:
                st.error(f"[{q}] DART API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                korea_sec_df = pd.DataFrame(columns=["íšŒì‚¬ëª…", "ë³´ê³ ì„œ ì¢…ë¥˜", "ê¸°ì¤€ì—°ë„/ë¶„ê¸°", "ì œì¶œì¼", "url"])
            else:
                with st.spinner(f"[{q}] DART ìˆ˜ì§‘ ì¤‘..."):
                    try:
                        rows = collect_dart_reports(q)
                        if rows:
                            korea_sec_df = pd.DataFrame(rows)
                            korea_sec_df["query"] = q
                        else:
                            korea_sec_df = pd.DataFrame(
                                columns=["íšŒì‚¬ëª…", "ë³´ê³ ì„œ ì¢…ë¥˜", "ê¸°ì¤€ì—°ë„/ë¶„ê¸°", "ì œì¶œì¼", "url", "query"]
                            )
                    except Exception as e:
                        if "DART_API_KEY" in str(e) or "ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤" in str(e):
                            st.error(f"[{q}] DART API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                        else:
                            errors.append(f"DART [{q}]: {e}")
                        korea_sec_df = pd.DataFrame(
                            columns=["íšŒì‚¬ëª…", "ë³´ê³ ì„œ ì¢…ë¥˜", "ê¸°ì¤€ì—°ë„/ë¶„ê¸°", "ì œì¶œì¼", "url", "query"]
                        )
        else:
            # ë¯¸êµ­ í‹°ì»¤ â†’ SEC
            with st.spinner(f"[{q}] SEC ìˆ˜ì§‘ ì¤‘..."):
                try:
                    rows = collect_sec_links(q.upper())
                    if rows:
                        sec_df = pd.DataFrame([
                            {
                                "query": q,
                                "ticker": r.get("ticker", ""),
                                "source_type": r.get("source_type", "SEC"),
                                "published_date": r.get("published_date", ""),
                                "url": r.get("url", ""),
                            }
                            for r in rows
                        ])
                    else:
                        sec_df = pd.DataFrame(
                            columns=["query", "ticker", "source_type", "published_date", "url"]
                        )
                except Exception as e:
                    errors.append(f"SEC [{q}]: {e}")
                    sec_df = pd.DataFrame(
                        columns=["query", "ticker", "source_type", "published_date", "url"]
                    )

    if "ìœ íŠœë¸Œ" in opts:
        with st.spinner(f"[{q}] ìœ íŠœë¸Œ ê²€ìƒ‰ ì¤‘..."):
            try:
                rows = search_youtube_videos(q, max_results=max_yt)
                if rows:
                    for r in rows:
                        r["query"] = q
                    yt_df = pd.DataFrame(rows)
                else:
                    yt_df = pd.DataFrame(
                        columns=["title", "url", "duration_minutes", "published_at", "query"]
                    )
            except Exception as e:
                errors.append(f"ìœ íŠœë¸Œ [{q}]: {e}")
                yt_df = pd.DataFrame(
                    columns=["title", "url", "duration_minutes", "published_at", "query"]
                )

    if "ë…¼ë¬¸" in opts:
        with st.spinner(f"[{q}] ë…¼ë¬¸ ê²€ìƒ‰ ì¤‘ (PDF ìˆëŠ” ë…¼ë¬¸ë§Œ)..."):
            try:
                rows = search_papers(q, max_results=max_paper)
                if rows:
                    for r in rows:
                        r.setdefault("query", q)
                    paper_df = pd.DataFrame(rows)
                else:
                    paper_df = pd.DataFrame(
                        columns=["title", "authors", "year", "venue", "citation_count",
                                 "is_open_access", "main_url", "pdf_url", "query"]
                    )
            except Exception as e:
                errors.append(f"ë…¼ë¬¸ [{q}]: {e}")
                paper_df = pd.DataFrame(
                    columns=["title", "authors", "year", "venue", "citation_count",
                             "is_open_access", "main_url", "pdf_url", "query"]
                )

    if "ë¦¬í¬íŠ¸" in opts:
        with st.spinner(f"[{q}] ë¦¬í¬íŠ¸ ê²€ìƒ‰ ì¤‘..."):
            try:
                rows = search_reports(q, max_results=max_report)
                if rows:
                    report_df = pd.DataFrame(rows)
                else:
                    report_df = pd.DataFrame(
                        columns=["source", "title", "url", "published_date", "snippet", "score", "query"]
                    )
            except Exception as e:
                errors.append(f"ë¦¬í¬íŠ¸ [{q}]: {e}")
                report_df = pd.DataFrame(
                    columns=["source", "title", "url", "published_date", "snippet", "score", "query"]
                )

    if "ë‰´ìŠ¤" in opts:
        if not news_api_configured():
            st.warning(
                "ë‰´ìŠ¤ ê²€ìƒ‰ì„ ì‚¬ìš©í•˜ë ¤ë©´ í™˜ê²½ë³€ìˆ˜ë¥¼ ì„¤ì •í•´ ì£¼ì„¸ìš”.\n"
                "ì˜ë¬¸ ë‰´ìŠ¤: `NEWS_API_KEY` (newsapi.org)\n"
                "í•œê¸€ ë‰´ìŠ¤: `NAVER_CLIENT_ID` + `NAVER_CLIENT_SECRET` (ë„¤ì´ë²„ ê²€ìƒ‰ API)"
            )
            news_df = pd.DataFrame(
                columns=["title", "url", "published_at", "source_name", "query"]
            )
        else:
            with st.spinner(f"[{q}] ë‰´ìŠ¤ ê²€ìƒ‰ ì¤‘..."):
                try:
                    rows = search_news_articles(q, max_results=max_news)
                    if rows:
                        news_df = pd.DataFrame(rows)
                    else:
                        news_df = pd.DataFrame(
                            columns=["title", "url", "published_at", "source_name", "query"]
                        )
                except Exception as e:
                    errors.append(f"ë‰´ìŠ¤ [{q}]: {e}")
                    news_df = pd.DataFrame(
                        columns=["title", "url", "published_at", "source_name", "query"]
                    )

    for err in errors:
        st.error(err)

    return sec_df, korea_sec_df, yt_df, paper_df, report_df, news_df


def _build_excel(opts, sec_df, korea_sec_df, yt_df, paper_df, report_df, news_df) -> bytes:
    buffer = BytesIO()
    with pd.ExcelWriter(buffer, engine="xlsxwriter") as writer:
        if ("ì¬ë¬´ì œí‘œ(SEC)" in opts or "ì¬ë¬´ì œí‘œ(DART)" in opts) and sec_df is not None:
            sec_df.to_excel(writer, sheet_name="SEC", index=False)
        if ("ì¬ë¬´ì œí‘œ(SEC)" in opts or "ì¬ë¬´ì œí‘œ(DART)" in opts) and korea_sec_df is not None:
            korea_sec_df.to_excel(writer, sheet_name="KOREA_SEC", index=False)
        if "ìœ íŠœë¸Œ" in opts and yt_df is not None:
            yt_df.to_excel(writer, sheet_name="YouTube", index=False)
        if "ë…¼ë¬¸" in opts and paper_df is not None:
            paper_df.to_excel(writer, sheet_name="Papers", index=False)
        if "ë¦¬í¬íŠ¸" in opts and report_df is not None:
            report_df.to_excel(writer, sheet_name="Reports", index=False)
        if "ë‰´ìŠ¤" in opts and news_df is not None:
            news_df.to_excel(writer, sheet_name="News", index=False)
    return buffer.getvalue()


# â”€â”€ ë‹¨ì¼ ê²€ìƒ‰ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if search_clicked:
    q = (query_input or "").strip()
    if not q:
        st.warning("ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•´ ì£¼ì„¸ìš”.")
    elif not options:
        st.warning("ìµœì†Œ í•˜ë‚˜ ì´ìƒì˜ ì†ŒìŠ¤ë¥¼ ì„ íƒí•´ ì£¼ì„¸ìš”.")
    else:
        sec_df, korea_sec_df, yt_df, paper_df, report_df, news_df = _run_single_search(
            q, options,
            max_yt=30, max_paper=30, max_report=30, max_news=30,
        )
        st.session_state.sec_df = sec_df
        st.session_state.korea_sec_df = korea_sec_df
        st.session_state.yt_df = yt_df
        st.session_state.paper_df = paper_df
        st.session_state.report_df = report_df
        st.session_state.news_df = news_df
        st.session_state.excel_bytes = _build_excel(
            options, sec_df, korea_sec_df, yt_df, paper_df, report_df, news_df
        )
        st.session_state.download_filename = f"research_{slugify(q)}.xlsx"

# â”€â”€ ë‹¤ì¤‘ ê²€ìƒ‰ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if multi_search_clicked:
    raw_queries = [line.strip() for line in (multi_query_input or "").splitlines() if line.strip()]
    if not raw_queries:
        st.warning("ë‹¤ì¤‘ ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•´ ì£¼ì„¸ìš”.")
    elif not options:
        st.warning("ìµœì†Œ í•˜ë‚˜ ì´ìƒì˜ ì†ŒìŠ¤ë¥¼ ì„ íƒí•´ ì£¼ì„¸ìš”.")
    else:
        all_sec = []
        all_korea_sec = []
        all_yt = []
        all_paper = []
        all_report = []
        all_news = []

        total = len(raw_queries)
        progress_bar = st.progress(0, text="ë‹¤ì¤‘ ê²€ìƒ‰ ì‹œì‘...")

        for idx, q in enumerate(raw_queries):
            progress_bar.progress(idx / total, text=f"[{idx + 1}/{total}] '{q}' ê²€ìƒ‰ ì¤‘...")
            sec_df, korea_sec_df, yt_df, paper_df, report_df, news_df = _run_single_search(
                q, options,
                max_yt=10, max_paper=10, max_report=10, max_news=10,
            )
            if sec_df is not None:
                all_sec.append(sec_df)
            if korea_sec_df is not None:
                all_korea_sec.append(korea_sec_df)
            if yt_df is not None:
                all_yt.append(yt_df)
            if paper_df is not None:
                all_paper.append(paper_df)
            if report_df is not None:
                all_report.append(report_df)
            if news_df is not None:
                all_news.append(news_df)

        progress_bar.progress(1.0, text="ë‹¤ì¤‘ ê²€ìƒ‰ ì™„ë£Œ!")

        sec_df = pd.concat(all_sec, ignore_index=True) if all_sec else None
        korea_sec_df = pd.concat(all_korea_sec, ignore_index=True) if all_korea_sec else None
        yt_df = pd.concat(all_yt, ignore_index=True) if all_yt else None
        paper_df = pd.concat(all_paper, ignore_index=True) if all_paper else None
        report_df = pd.concat(all_report, ignore_index=True) if all_report else None
        news_df = pd.concat(all_news, ignore_index=True) if all_news else None

        st.session_state.sec_df = sec_df
        st.session_state.korea_sec_df = korea_sec_df
        st.session_state.yt_df = yt_df
        st.session_state.paper_df = paper_df
        st.session_state.report_df = report_df
        st.session_state.news_df = news_df

        slug = slugify("_".join(raw_queries[:3]))
        st.session_state.excel_bytes = _build_excel(
            options, sec_df, korea_sec_df, yt_df, paper_df, report_df, news_df
        )
        st.session_state.download_filename = f"research_multi_{slug}.xlsx"

# â”€â”€ ë¦¬ì„œì¹˜ ë³´ì¡° ë„êµ¬ (ì‚¬ì´ë“œë°”) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.sidebar.markdown("## ë¦¬ì„œì¹˜ ë³´ì¡° ë„êµ¬")

_TOOLS = [
    ("ChatGPT", "https://chat.openai.com", "chatgpt.png.png"),
    ("Google Gemini", "https://gemini.google.com", "gemini.png.png"),
    ("Anthropic Claude", "https://claude.ai", "claude.png.png"),
    ("Google NotebookLM", "https://notebooklm.google.com", "notebooklm.png.png"),
]

_tool_items_html = ""
for _label, _url, _logo in _TOOLS:
    _b64 = _img_b64(_logo)
    _icon_html = (
        f'<img src="{_b64}" style="width:20px;height:20px;object-fit:contain;flex-shrink:0;" />'
        if _b64 else
        '<span style="width:20px;height:20px;display:inline-block;"></span>'
    )
    _tool_items_html += f"""
    <a href="{_url}" target="_blank" rel="noopener noreferrer" style="
        display:flex; align-items:center; gap:10px;
        padding:10px 12px; border-radius:10px;
        border:1px solid rgba(255,255,255,0.10);
        text-decoration:none; color:inherit;
        background:rgba(255,255,255,0.02);
        margin-bottom:8px;
        transition:background 120ms ease;
    ">
      {_icon_html}
      <span style="font-size:14px;">{_label}</span>
    </a>"""

st.sidebar.markdown(_tool_items_html, unsafe_allow_html=True)

# â”€â”€ ë„¤ì´ë²„ ë¸”ë¡œê·¸ ë°°ë„ˆ (ì‚¬ì´ë“œë°”) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.sidebar.markdown(
    """
    <a href="https://blog.naver.com/hanryang72" target="_blank" rel="noopener noreferrer"
       style="display:block; text-decoration:none; color:inherit;">
      <div style="
        margin-top:8px;
        padding:14px 16px;
        border-radius:12px;
        background:rgba(255,255,255,0.04);
        border:1px solid rgba(255,255,255,0.10);
        transition:background 140ms ease;
      ">
        <div style="display:flex; align-items:center; gap:10px; margin-bottom:6px;">
          <div style="
            width:26px; height:26px; border-radius:8px;
            background:rgba(3,199,90,0.18);
            border:1px solid rgba(3,199,90,0.35);
            display:flex; align-items:center; justify-content:center;
            font-size:13px; font-weight:800; color:#03c75a;
          ">N</div>
          <span style="font-size:14px; font-weight:800;">ACresearch ì„¼í„°</span>
        </div>
        <div style="font-size:12px; opacity:0.7; line-height:1.5;">
          ACresearchë¡œ ë§Œë“  ì •ë³´ë¥¼ ê³µìœ í•˜ëŠ” ë¸”ë¡œê·¸ì…ë‹ˆë‹¤.
        </div>
      </div>
    </a>
    """,
    unsafe_allow_html=True,
)

# â”€â”€ ì—‘ì…€ ë‹¤ìš´ë¡œë“œ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if st.session_state.excel_bytes:
    st.download_button(
        label="ì—‘ì…€ íŒŒì¼ ë‹¤ìš´ë¡œë“œ",
        data=st.session_state.excel_bytes,
        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
        file_name=st.session_state.download_filename,
        key="download_excel",
    )

# â”€â”€ ê²€ìƒ‰ ê²°ê³¼ í…Œì´ë¸” â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def _url_col(df: pd.DataFrame) -> str | None:
    """dfì—ì„œ URL ì»¬ëŸ¼ ì´ë¦„ì„ ë°˜í™˜. ìš°ì„ ìˆœìœ„: url â†’ pdf_url â†’ main_url â†’ None."""
    for c in ["url", "pdf_url", "main_url"]:
        if c in df.columns:
            return c
    return None


def _show_table(title: str, df: pd.DataFrame, url_key: str) -> None:
    """ì œëª©(+ ë¹¨ê°„ Copy URLs ë²„íŠ¼ inline) + ë°ì´í„°í”„ë ˆì„ ë Œë”ë§."""
    import json

    col = _url_col(df)
    urls: list[str] = []
    if col:
        urls = [u for u in df[col].dropna().astype(str).str.strip() if u]
    n = len(urls)

    if urls:
        urls_json = json.dumps(urls)
        components.html(
            f"""
            <style>
              #btn_{url_key} {{
                display: inline-block;
                padding: 4px 13px;
                font-size: 12px;
                font-weight: 600;
                border-radius: 6px;
                border: none;
                background: #FF4B4B;
                color: #ffffff;
                cursor: pointer;
                white-space: nowrap;
                vertical-align: middle;
                transition: background 120ms ease, opacity 120ms ease;
                font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", sans-serif;
              }}
              #btn_{url_key}:hover {{ background: #e03c3c; }}
              #btn_{url_key}:active {{ opacity: 0.8; }}
            </style>
            <div style="display:flex; align-items:center; gap:10px; margin:0; padding:2px 0;">
              <span style="
                font-size: 1.3rem;
                font-weight: 700;
                color: #e6edf3;
                line-height: 1.4;
                font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', sans-serif;
              ">{title}</span>
              <button id="btn_{url_key}">ğŸ”— Copy URLs ({n}ê°œ)</button>
            </div>
            <script>
            (function(){{
              var urls = {urls_json};
              var btn  = document.getElementById('btn_{url_key}');
              btn.addEventListener('click', function(){{
                var text = urls.join('\\n');
                var orig = btn.innerText;
                navigator.clipboard.writeText(text).then(function(){{
                  btn.innerText = 'âœ… ë³µì‚¬ë¨ ({n}ê°œ)';
                  btn.style.background = '#2ea043';
                  setTimeout(function(){{
                    btn.innerText = orig;
                    btn.style.background = '#FF4B4B';
                  }}, 2000);
                }}).catch(function(){{
                  var ta = document.createElement('textarea');
                  ta.value = text;
                  document.body.appendChild(ta);
                  ta.select();
                  document.execCommand('copy');
                  document.body.removeChild(ta);
                  btn.innerText = 'âœ… ë³µì‚¬ë¨ ({n}ê°œ)';
                  btn.style.background = '#2ea043';
                  setTimeout(function(){{
                    btn.innerText = orig;
                    btn.style.background = '#FF4B4B';
                  }}, 2000);
                }});
              }});
            }})();
            </script>
            """,
            height=48,
            scrolling=False,
        )
    else:
        st.subheader(title)

    st.dataframe(df, use_container_width=True)


if st.session_state.sec_df is not None:
    _show_table("SEC ê²°ê³¼ (ë¯¸êµ­)", st.session_state.sec_df, "copy_sec")

if st.session_state.korea_sec_df is not None:
    _show_table("DART ê²°ê³¼ (êµ­ë‚´)", st.session_state.korea_sec_df, "copy_dart")

if st.session_state.yt_df is not None:
    _show_table("YouTube ê²°ê³¼", st.session_state.yt_df, "copy_yt")

if st.session_state.paper_df is not None:
    _show_table("ë…¼ë¬¸ ê²°ê³¼ (PDF URL ìˆëŠ” ë…¼ë¬¸ë§Œ)", st.session_state.paper_df, "copy_paper")

if st.session_state.report_df is not None:
    _show_table("ë¦¬í¬íŠ¸ ê²°ê³¼", st.session_state.report_df, "copy_report")

if st.session_state.news_df is not None:
    _show_table("ë‰´ìŠ¤ ê²°ê³¼", st.session_state.news_df, "copy_news")

# â”€â”€ ì‚¬ìš© ì•ˆë‚´ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.markdown("---")
st.subheader("ì‚¬ìš© ì•ˆë‚´")
st.markdown("""
**ì¬ë¬´ì œí‘œ ê²€ìƒ‰ ì•ˆë‚´**

ì¬ë¬´ì œí‘œ ê²€ìƒ‰ ì‹œ ë¯¸êµ­ ì£¼ì‹ì€ í‹°ì»¤(symbol), êµ­ë‚´ ì£¼ì‹ì€ ì¢…ëª©ë²ˆí˜¸ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì¡°íšŒë©ë‹ˆë‹¤. ì •í™•í•œ ê²€ìƒ‰ì„ ìœ„í•´ í‹°ì»¤ ë˜ëŠ” ì¢…ëª©ë²ˆí˜¸ë§Œ ë‹¨ë…ìœ¼ë¡œ ì…ë ¥í•˜ëŠ” ê²ƒì„ ê¶Œì¥í•©ë‹ˆë‹¤.

ìœ íŠœë¸Œ ì˜ìƒì´ë‚˜ ë…¼ë¬¸ì„ ê²€ìƒ‰í•  ë•Œ í‹°ì»¤ ë˜ëŠ” ì¢…ëª©ë²ˆí˜¸ë§Œìœ¼ë¡œ ê²€ìƒ‰í•˜ë©´ ì›í•˜ëŠ” ê²°ê³¼ê°€ ì •í™•íˆ ë‚˜ì˜¤ì§€ ì•Šì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ ê²½ìš°ì—ëŠ” ê¸°ì—…ëª… ë˜ëŠ” ê´€ë ¨ í‚¤ì›Œë“œë¥¼ í•¨ê»˜ í™œìš©í•´ ê²€ìƒ‰í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.

**ë‰´ìŠ¤ ê²€ìƒ‰ ì•ˆë‚´**

ë‰´ìŠ¤ëŠ” í•œê¸€ ì¿¼ë¦¬ì´ë©´ NAVER ë‰´ìŠ¤ API, ì˜ë¬¸ ì¿¼ë¦¬ì´ë©´ NewsAPI.orgë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤. í™˜ê²½ë³€ìˆ˜(NAVER_CLIENT_ID, NAVER_CLIENT_SECRET, NEWS_API_KEY)ê°€ ì„¤ì •ë˜ì–´ ìˆì–´ì•¼ í•©ë‹ˆë‹¤.

**ì‚¬ìš© ë°©ë²• (Notebook LM ê¸°ì¤€)**

1. Notebook LMì— ì ‘ì†í•˜ì—¬ ìƒˆ ë…¸íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
2. ì¢Œì¸¡ì˜ ì†ŒìŠ¤ ì¶”ê°€ ë²„íŠ¼ì„ í´ë¦­í•œ ë’¤ ì›¹ì‚¬ì´íŠ¸ë¥¼ ì„ íƒí•©ë‹ˆë‹¤.
3. í”„ë¡œê·¸ë¨ì—ì„œ ê²€ìƒ‰ëœ URLì„ ë³µì‚¬í•´ ë¶™ì—¬ë„£ê³  ì¶”ê°€í•©ë‹ˆë‹¤.
4. ì†ŒìŠ¤ ì¶”ê°€ê°€ ì™„ë£Œë˜ë©´ ê¶ê¸ˆí•œ ë‚´ìš©ì„ ì§ˆë¬¸í•˜ê±°ë‚˜, ìŠ¤íŠœë””ì˜¤ ê¸°ëŠ¥ì„ ì‹¤í–‰í•˜ì—¬ ë¶„ì„ì„ ì§„í–‰í•©ë‹ˆë‹¤.

ë‹¤ë¥¸ AI í”Œë«í¼ì—ì„œë„ ë™ì¼í•œ ë°©ì‹ìœ¼ë¡œ URLì„ ì¶”ê°€í•´ í™œìš©í•˜ì‹œë©´ ë©ë‹ˆë‹¤.
""")
